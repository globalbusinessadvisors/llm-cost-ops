# Default values for llm-cost-ops Helm chart

replicaCount: 3

image:
  repository: ghcr.io/your-org/llm-cost-ops
  pullPolicy: IfNotPresent
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "9090"
  prometheus.io/path: "/metrics"

podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL

service:
  type: ClusterIP
  port: 80
  metricsPort: 9090
  annotations: {}
  sessionAffinity: ClientIP

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/limit-rps: "100"
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
  hosts:
    - host: api.llm-cost-ops.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: llm-cost-ops-tls
      hosts:
        - api.llm-cost-ops.example.com

resources:
  limits:
    memory: "2Gi"
    cpu: "2000m"
  requests:
    memory: "512Mi"
    cpu: "500m"

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30

podDisruptionBudget:
  enabled: true
  minAvailable: 2

networkPolicy:
  enabled: true
  policyTypes:
    - Ingress
    - Egress

livenessProbe:
  httpGet:
    path: /live
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

startupProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 0
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 30

nodeSelector: {}

tolerations: []

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - llm-cost-ops
        topologyKey: kubernetes.io/hostname

config:
  environment: production
  logLevel: info
  logFormat: json
  serverHost: "0.0.0.0"
  serverPort: 8080
  metricsPort: 9090

  metrics:
    enabled: true
    endpoint: "/metrics"
    includeProcessMetrics: true

  tracing:
    enabled: true
    level: info
    format: json
    ansi: false

  health:
    enabled: true
    endpoint: "/health"
    checkInterval: 30
    readinessEndpoint: "/ready"
    livenessEndpoint: "/live"

  features:
    forecastingEnabled: true
    anomalyDetectionEnabled: true
    budgetAlertsEnabled: true
    webhookEnabled: true

  rateLimit:
    enabled: true
    requestsPerSecond: 100
    burstSize: 200

  compression:
    enabled: true
    level: 6
    minSize: 1024

  cache:
    enabled: true
    ttlSeconds: 3600
    maxSizeMb: 512

  dlq:
    enabled: true
    maxRetries: 3
    retryDelayMs: 1000
    backoffMultiplier: 2

  rbac:
    enabled: true

  audit:
    enabled: true
    logLevel: info

secrets:
  create: true
  existingSecret: ""
  databaseUrl: "postgresql://llm_cost_ops:changeme@postgres:5432/llm_cost_ops"
  jwtSecret: "changeme-use-strong-random-secret"
  jwtExpirationHours: 24
  webhookSigningSecret: "changeme"
  encryptionKey: "changeme-32-byte-key"

monitoring:
  serviceMonitor:
    enabled: true
    interval: 30s
    scrapeTimeout: 10s

persistence:
  enabled: false
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 10Gi

initContainers:
  migrate:
    enabled: true
    image:
      repository: ghcr.io/your-org/llm-cost-ops
      tag: "latest"
    resources:
      limits:
        memory: "256Mi"
        cpu: "500m"
      requests:
        memory: "128Mi"
        cpu: "100m"

postgresql:
  enabled: false
  auth:
    postgresPassword: changeme
    database: llm_cost_ops
  primary:
    persistence:
      enabled: true
      size: 20Gi

redis:
  enabled: false
  auth:
    password: changeme
  master:
    persistence:
      enabled: true
      size: 8Gi

extraEnvVars: []
extraEnvVarsSecret: ""
extraVolumes: []
extraVolumeMounts: []
