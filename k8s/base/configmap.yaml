apiVersion: v1
kind: ConfigMap
metadata:
  name: llm-cost-ops-config
  labels:
    app: llm-cost-ops
    component: api
data:
  # Application configuration
  APP_NAME: "llm-cost-ops"
  ENVIRONMENT: "production"
  LOG_LEVEL: "info"
  LOG_FORMAT: "json"

  # Server configuration
  SERVER_HOST: "0.0.0.0"
  SERVER_PORT: "8080"
  METRICS_PORT: "9090"

  # Observability configuration
  METRICS_ENABLED: "true"
  METRICS_ENDPOINT: "/metrics"
  METRICS_PROCESS: "true"

  TRACING_ENABLED: "true"
  TRACING_LEVEL: "info"
  TRACING_FORMAT: "json"
  TRACING_ANSI: "false"

  HEALTH_ENABLED: "true"
  HEALTH_ENDPOINT: "/health"
  HEALTH_CHECK_INTERVAL: "30"
  READINESS_ENDPOINT: "/ready"
  LIVENESS_ENDPOINT: "/live"

  # OTLP configuration (OpenTelemetry)
  OTEL_SERVICE_NAME: "llm-cost-ops"
  OTEL_SERVICE_VERSION: "0.1.0"

  # Rate limiting
  RATE_LIMIT_ENABLED: "true"
  RATE_LIMIT_REQUESTS_PER_SECOND: "100"
  RATE_LIMIT_BURST_SIZE: "200"

  # Compression
  COMPRESSION_ENABLED: "true"
  COMPRESSION_LEVEL: "6"
  COMPRESSION_MIN_SIZE: "1024"

  # Cache configuration
  CACHE_ENABLED: "true"
  CACHE_TTL_SECONDS: "3600"
  CACHE_MAX_SIZE_MB: "512"

  # DLQ configuration
  DLQ_ENABLED: "true"
  DLQ_MAX_RETRIES: "3"
  DLQ_RETRY_DELAY_MS: "1000"
  DLQ_BACKOFF_MULTIPLIER: "2"

  # RBAC configuration
  RBAC_ENABLED: "true"
  AUDIT_ENABLED: "true"
  AUDIT_LOG_LEVEL: "info"

  # Feature flags
  FORECASTING_ENABLED: "true"
  ANOMALY_DETECTION_ENABLED: "true"
  BUDGET_ALERTS_ENABLED: "true"

  # Integration settings
  WEBHOOK_ENABLED: "true"
  WEBHOOK_TIMEOUT_SECONDS: "30"
  WEBHOOK_MAX_RETRIES: "3"
