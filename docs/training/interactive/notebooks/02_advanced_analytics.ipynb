{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Analytics and Forecasting\n",
    "\n",
    "This notebook covers advanced statistical analysis and forecasting techniques for LLM cost prediction.\n",
    "\n",
    "## Learning Objectives\n",
    "- Perform statistical analysis on cost data\n",
    "- Detect trends and seasonality\n",
    "- Forecast future costs using Prophet\n",
    "- Identify anomalies and outliers\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install pandas matplotlib prophet scipy scikit-learn statsmodels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prophet for time series forecasting\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Prophet not available. Install with: pip install prophet\")\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "# Statsmodels for statistical analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "BASE_URL = 'http://localhost:3000/api'\n",
    "API_KEY = 'your-api-key-here'\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Fetch 90 days of data for better analysis\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "\n",
    "params = {\n",
    "    'start_date': start_date.isoformat(),\n",
    "    'end_date': end_date.isoformat(),\n",
    "    'limit': 5000\n",
    "}\n",
    "\n",
    "response = requests.get(f'{BASE_URL}/cost-tracking', headers=HEADERS, params=params)\n",
    "cost_data = response.json()\n",
    "\n",
    "df = pd.DataFrame(cost_data['data'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "print(f\"Loaded {len(df)} records from {start_date.date()} to {end_date.date()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare daily aggregated data\n",
    "daily_df = df.groupby('date').agg({\n",
    "    'total_cost': 'sum',\n",
    "    'input_tokens': 'sum',\n",
    "    'output_tokens': 'sum',\n",
    "    'request_id': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "daily_df.columns = ['date', 'total_cost', 'input_tokens', 'output_tokens', 'request_count']\n",
    "daily_df['total_tokens'] = daily_df['input_tokens'] + daily_df['output_tokens']\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df = daily_df.set_index('date').sort_index()\n",
    "\n",
    "print(f\"Daily aggregated data: {len(daily_df)} days\")\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(\"Daily Cost Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Mean: ${daily_df['total_cost'].mean():.2f}\")\n",
    "print(f\"Median: ${daily_df['total_cost'].median():.2f}\")\n",
    "print(f\"Std Dev: ${daily_df['total_cost'].std():.2f}\")\n",
    "print(f\"Min: ${daily_df['total_cost'].min():.2f}\")\n",
    "print(f\"Max: ${daily_df['total_cost'].max():.2f}\")\n",
    "print(f\"\\nSkewness: {daily_df['total_cost'].skew():.2f}\")\n",
    "print(f\"Kurtosis: {daily_df['total_cost'].kurtosis():.2f}\")\n",
    "\n",
    "# Coefficient of variation\n",
    "cv = (daily_df['total_cost'].std() / daily_df['total_cost'].mean()) * 100\n",
    "print(f\"\\nCoefficient of Variation: {cv:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality\n",
    "statistic, p_value = stats.normaltest(daily_df['total_cost'])\n",
    "print(f\"Normality Test (D'Agostino-Pearson):\")\n",
    "print(f\"Test Statistic: {statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Result: {'Normally distributed' if p_value > 0.05 else 'Not normally distributed'} (α=0.05)\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram with normal distribution overlay\n",
    "axes[0].hist(daily_df['total_cost'], bins=30, density=True, alpha=0.7, edgecolor='black')\n",
    "mu, sigma = daily_df['total_cost'].mean(), daily_df['total_cost'].std()\n",
    "x = np.linspace(daily_df['total_cost'].min(), daily_df['total_cost'].max(), 100)\n",
    "axes[0].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal Distribution')\n",
    "axes[0].set_title('Daily Cost Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Daily Cost ($)')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].legend()\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(daily_df['total_cost'], dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trend Detection and Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dickey-Fuller test for stationarity\n",
    "result = adfuller(daily_df['total_cost'].dropna())\n",
    "print(\"Augmented Dickey-Fuller Test:\")\n",
    "print(f\"ADF Statistic: {result[0]:.4f}\")\n",
    "print(f\"P-value: {result[1]:.4f}\")\n",
    "print(f\"Critical Values:\")\n",
    "for key, value in result[4].items():\n",
    "    print(f\"  {key}: {value:.3f}\")\n",
    "print(f\"\\nResult: {'Stationary' if result[1] < 0.05 else 'Non-stationary'} (α=0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series decomposition (if we have enough data)\n",
    "if len(daily_df) >= 14:\n",
    "    decomposition = seasonal_decompose(daily_df['total_cost'], model='additive', period=7)\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 10))\n",
    "    \n",
    "    decomposition.observed.plot(ax=axes[0], title='Observed', color='blue')\n",
    "    axes[0].set_ylabel('Cost ($)')\n",
    "    \n",
    "    decomposition.trend.plot(ax=axes[1], title='Trend', color='red')\n",
    "    axes[1].set_ylabel('Cost ($)')\n",
    "    \n",
    "    decomposition.seasonal.plot(ax=axes[2], title='Seasonal (Weekly)', color='green')\n",
    "    axes[2].set_ylabel('Cost ($)')\n",
    "    \n",
    "    decomposition.resid.plot(ax=axes[3], title='Residual', color='orange')\n",
    "    axes[3].set_ylabel('Cost ($)')\n",
    "    axes[3].set_xlabel('Date')\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Time Series Decomposition', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for seasonal decomposition (need at least 14 days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rolling Statistics and Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "daily_df['ma_7'] = daily_df['total_cost'].rolling(window=7).mean()\n",
    "daily_df['ma_14'] = daily_df['total_cost'].rolling(window=14).mean()\n",
    "daily_df['rolling_std_7'] = daily_df['total_cost'].rolling(window=7).std()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(daily_df.index, daily_df['total_cost'], label='Daily Cost', alpha=0.5, marker='o', markersize=3)\n",
    "ax.plot(daily_df.index, daily_df['ma_7'], label='7-Day MA', linewidth=2)\n",
    "ax.plot(daily_df.index, daily_df['ma_14'], label='14-Day MA', linewidth=2)\n",
    "\n",
    "ax.set_title('Cost Trends with Moving Averages', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Cost ($)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility analysis\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(daily_df.index, daily_df['rolling_std_7'], label='7-Day Rolling Std Dev', \n",
    "        linewidth=2, color='coral')\n",
    "ax.fill_between(daily_df.index, daily_df['rolling_std_7'], alpha=0.3, color='coral')\n",
    "\n",
    "ax.set_title('Cost Volatility (7-Day Rolling Standard Deviation)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Standard Deviation ($)', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Daily Volatility: ${daily_df['rolling_std_7'].mean():.2f}\")\n",
    "print(f\"Maximum Volatility: ${daily_df['rolling_std_7'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical anomaly detection using Z-score\n",
    "daily_df['z_score'] = np.abs(stats.zscore(daily_df['total_cost']))\n",
    "daily_df['is_outlier_zscore'] = daily_df['z_score'] > 3\n",
    "\n",
    "# IQR method\n",
    "Q1 = daily_df['total_cost'].quantile(0.25)\n",
    "Q3 = daily_df['total_cost'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "daily_df['is_outlier_iqr'] = (daily_df['total_cost'] < lower_bound) | (daily_df['total_cost'] > upper_bound)\n",
    "\n",
    "# Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "daily_df['is_outlier_iforest'] = iso_forest.fit_predict(daily_df[['total_cost']].values) == -1\n",
    "\n",
    "print(\"Anomaly Detection Results:\")\n",
    "print(f\"Z-Score method (|z| > 3): {daily_df['is_outlier_zscore'].sum()} anomalies\")\n",
    "print(f\"IQR method: {daily_df['is_outlier_iqr'].sum()} anomalies\")\n",
    "print(f\"Isolation Forest: {daily_df['is_outlier_iforest'].sum()} anomalies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize anomalies\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "methods = [\n",
    "    ('is_outlier_zscore', 'Z-Score Method (|z| > 3)'),\n",
    "    ('is_outlier_iqr', 'IQR Method'),\n",
    "    ('is_outlier_iforest', 'Isolation Forest')\n",
    "]\n",
    "\n",
    "for idx, (col, title) in enumerate(methods):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot normal points\n",
    "    normal = daily_df[~daily_df[col]]\n",
    "    ax.scatter(normal.index, normal['total_cost'], alpha=0.6, s=50, label='Normal')\n",
    "    \n",
    "    # Plot anomalies\n",
    "    anomalies = daily_df[daily_df[col]]\n",
    "    if len(anomalies) > 0:\n",
    "        ax.scatter(anomalies.index, anomalies['total_cost'], \n",
    "                  color='red', s=100, marker='X', label='Anomaly', zorder=5)\n",
    "    \n",
    "    ax.set_title(f'Anomaly Detection: {title}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Daily Cost ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed anomaly report\n",
    "anomalies = daily_df[daily_df['is_outlier_zscore'] | daily_df['is_outlier_iqr'] | daily_df['is_outlier_iforest']]\n",
    "\n",
    "if len(anomalies) > 0:\n",
    "    print(\"\\nDetailed Anomaly Report:\")\n",
    "    print(\"=\"*80)\n",
    "    for date, row in anomalies.iterrows():\n",
    "        print(f\"\\nDate: {date.date()}\")\n",
    "        print(f\"  Cost: ${row['total_cost']:.2f}\")\n",
    "        print(f\"  Z-Score: {row['z_score']:.2f}\")\n",
    "        print(f\"  Requests: {row['request_count']:.0f}\")\n",
    "        print(f\"  Total Tokens: {row['total_tokens']:.0f}\")\n",
    "        print(f\"  Detection Methods: \", end=\"\")\n",
    "        methods_detected = []\n",
    "        if row['is_outlier_zscore']: methods_detected.append('Z-Score')\n",
    "        if row['is_outlier_iqr']: methods_detected.append('IQR')\n",
    "        if row['is_outlier_iforest']: methods_detected.append('Isolation Forest')\n",
    "        print(', '.join(methods_detected))\n",
    "else:\n",
    "    print(\"No anomalies detected in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cost Forecasting with Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Prepare data for Prophet\n",
    "    prophet_df = daily_df.reset_index()[['date', 'total_cost']]\n",
    "    prophet_df.columns = ['ds', 'y']\n",
    "    \n",
    "    # Create and fit model\n",
    "    model = Prophet(\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False if len(prophet_df) < 365 else True,\n",
    "        changepoint_prior_scale=0.05\n",
    "    )\n",
    "    \n",
    "    model.fit(prophet_df)\n",
    "    print(\"Prophet model trained successfully!\")\n",
    "    \n",
    "    # Make future predictions (30 days)\n",
    "    future = model.make_future_dataframe(periods=30)\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    print(f\"\\nForecast created for next 30 days\")\n",
    "    print(f\"Predicted total cost for next 30 days: ${forecast.tail(30)['yhat'].sum():.2f}\")\n",
    "else:\n",
    "    print(\"Prophet not available. Skipping forecasting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Plot forecast\n",
    "    fig = model.plot(forecast, figsize=(14, 6))\n",
    "    ax = fig.gca()\n",
    "    ax.set_title('Cost Forecast (30 Days)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Date', fontsize=12)\n",
    "    ax.set_ylabel('Daily Cost ($)', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot components\n",
    "    fig = model.plot_components(forecast, figsize=(14, 8))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Forecast summary\n",
    "    future_forecast = forecast.tail(30)\n",
    "    \n",
    "    print(\"\\n30-Day Forecast Summary:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Expected Daily Average: ${future_forecast['yhat'].mean():.2f}\")\n",
    "    print(f\"Expected Total Cost: ${future_forecast['yhat'].sum():.2f}\")\n",
    "    print(f\"\\nConfidence Interval (95%):\")\n",
    "    print(f\"  Lower Bound (Total): ${future_forecast['yhat_lower'].sum():.2f}\")\n",
    "    print(f\"  Upper Bound (Total): ${future_forecast['yhat_upper'].sum():.2f}\")\n",
    "    print(f\"\\nHighest Expected Day: ${future_forecast['yhat'].max():.2f} on {future_forecast.loc[future_forecast['yhat'].idxmax(), 'ds'].date()}\")\n",
    "    print(f\"Lowest Expected Day: ${future_forecast['yhat'].min():.2f} on {future_forecast.loc[future_forecast['yhat'].idxmin(), 'ds'].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "correlation_cols = ['total_cost', 'request_count', 'total_tokens', 'input_tokens', 'output_tokens']\n",
    "correlation_matrix = daily_df[correlation_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Correlations with Total Cost:\")\n",
    "print(correlation_matrix['total_cost'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Growth Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate week-over-week growth\n",
    "daily_df['cost_pct_change'] = daily_df['total_cost'].pct_change() * 100\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly_df = daily_df.resample('W').agg({\n",
    "    'total_cost': 'sum',\n",
    "    'request_count': 'sum',\n",
    "    'total_tokens': 'sum'\n",
    "})\n",
    "\n",
    "weekly_df['wow_growth'] = weekly_df['total_cost'].pct_change() * 100\n",
    "\n",
    "print(\"Week-over-Week Growth Rates:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in weekly_df.iterrows():\n",
    "    if pd.notna(row['wow_growth']):\n",
    "        print(f\"Week ending {idx.date()}: {row['wow_growth']:+.1f}% (${row['total_cost']:.2f})\")\n",
    "\n",
    "avg_growth = weekly_df['wow_growth'].mean()\n",
    "print(f\"\\nAverage Weekly Growth Rate: {avg_growth:+.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize growth\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Weekly costs with growth\n",
    "ax1 = axes[0]\n",
    "ax1.bar(weekly_df.index, weekly_df['total_cost'], alpha=0.7, width=5)\n",
    "ax1.set_title('Weekly Total Costs', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Cost ($)')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Growth rate\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if x >= 0 else 'red' for x in weekly_df['wow_growth']]\n",
    "ax2.bar(weekly_df.index, weekly_df['wow_growth'], alpha=0.7, width=5, color=colors)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_title('Week-over-Week Growth Rate', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Growth Rate (%)')\n",
    "ax2.set_xlabel('Week Ending')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "output_dir = 'advanced_analytics_output'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export anomalies\n",
    "if len(anomalies) > 0:\n",
    "    anomalies.to_csv(f'{output_dir}/anomalies.csv')\n",
    "    print(f\"Saved: {output_dir}/anomalies.csv\")\n",
    "\n",
    "# Export forecast\n",
    "if PROPHET_AVAILABLE:\n",
    "    future_forecast.to_csv(f'{output_dir}/forecast_30days.csv', index=False)\n",
    "    print(f\"Saved: {output_dir}/forecast_30days.csv\")\n",
    "\n",
    "# Export weekly summary\n",
    "weekly_df.to_csv(f'{output_dir}/weekly_summary.csv')\n",
    "print(f\"Saved: {output_dir}/weekly_summary.csv\")\n",
    "\n",
    "# Export correlation matrix\n",
    "correlation_matrix.to_csv(f'{output_dir}/correlation_matrix.csv')\n",
    "print(f\"Saved: {output_dir}/correlation_matrix.csv\")\n",
    "\n",
    "print(f\"\\nAll results exported to '{output_dir}/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- Statistical analysis techniques for cost data\n",
    "- Trend detection and time series decomposition\n",
    "- Multiple anomaly detection methods\n",
    "- Cost forecasting using Prophet\n",
    "- Correlation and growth rate analysis\n",
    "\n",
    "## Next Steps\n",
    "- **03_cost_optimization.ipynb** - Apply insights for cost optimization\n",
    "- **04_custom_reports.ipynb** - Build custom reporting dashboards\n",
    "- **05_ml_forecasting.ipynb** - Advanced ML forecasting techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
