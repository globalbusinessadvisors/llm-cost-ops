{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Cost Forecasting\n",
    "\n",
    "This notebook demonstrates advanced machine learning techniques for LLM cost prediction and forecasting.\n",
    "\n",
    "## Learning Objectives\n",
    "- Feature engineering for time series forecasting\n",
    "- Training multiple forecasting models (ARIMA, Prophet, LSTM)\n",
    "- Model evaluation and comparison\n",
    "- Production deployment considerations\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install pandas numpy matplotlib scikit-learn prophet statsmodels tensorflow keras\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Statistical models\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Prophet\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "    PROPHET_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Prophet not available. Install with: pip install prophet\")\n",
    "    PROPHET_AVAILABLE = False\n",
    "\n",
    "# Deep Learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    TENSORFLOW_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"TensorFlow not available. Install with: pip install tensorflow\")\n",
    "    TENSORFLOW_AVAILABLE = False\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "BASE_URL = 'http://localhost:3000/api'\n",
    "API_KEY = 'your-api-key-here'\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Fetch 90 days of data for training\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=90)\n",
    "\n",
    "params = {\n",
    "    'start_date': start_date.isoformat(),\n",
    "    'end_date': end_date.isoformat(),\n",
    "    'limit': 10000\n",
    "}\n",
    "\n",
    "response = requests.get(f'{BASE_URL}/cost-tracking', headers=HEADERS, params=params)\n",
    "cost_data = response.json()\n",
    "\n",
    "df = pd.DataFrame(cost_data['data'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['total_tokens'] = df['input_tokens'] + df['output_tokens']\n",
    "\n",
    "# Aggregate to daily level\n",
    "daily_df = df.groupby(df['timestamp'].dt.date).agg({\n",
    "    'total_cost': 'sum',\n",
    "    'request_id': 'count',\n",
    "    'total_tokens': 'sum',\n",
    "    'input_tokens': 'sum',\n",
    "    'output_tokens': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "daily_df.columns = ['date', 'total_cost', 'request_count', 'total_tokens', \n",
    "                    'input_tokens', 'output_tokens']\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df = daily_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(daily_df)} days of data\")\n",
    "print(f\"Date range: {daily_df['date'].min()} to {daily_df['date'].max()}\")\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "daily_df['day_of_week'] = daily_df['date'].dt.dayofweek\n",
    "daily_df['day_of_month'] = daily_df['date'].dt.day\n",
    "daily_df['week_of_year'] = daily_df['date'].dt.isocalendar().week\n",
    "daily_df['month'] = daily_df['date'].dt.month\n",
    "daily_df['is_weekend'] = daily_df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Lag features\n",
    "for lag in [1, 3, 7, 14]:\n",
    "    daily_df[f'cost_lag_{lag}'] = daily_df['total_cost'].shift(lag)\n",
    "    daily_df[f'requests_lag_{lag}'] = daily_df['request_count'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "for window in [7, 14, 30]:\n",
    "    daily_df[f'cost_ma_{window}'] = daily_df['total_cost'].rolling(window=window, min_periods=1).mean()\n",
    "    daily_df[f'cost_std_{window}'] = daily_df['total_cost'].rolling(window=window, min_periods=1).std()\n",
    "\n",
    "# Exponential moving average\n",
    "daily_df['cost_ema_7'] = daily_df['total_cost'].ewm(span=7, adjust=False).mean()\n",
    "daily_df['cost_ema_14'] = daily_df['total_cost'].ewm(span=14, adjust=False).mean()\n",
    "\n",
    "# Trend feature\n",
    "daily_df['trend'] = range(len(daily_df))\n",
    "\n",
    "print(\"Feature engineering complete!\")\n",
    "print(f\"Total features: {len(daily_df.columns)}\")\n",
    "print(f\"\\nFeature list: {daily_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Original cost\n",
    "axes[0, 0].plot(daily_df['date'], daily_df['total_cost'], label='Original', alpha=0.7)\n",
    "axes[0, 0].plot(daily_df['date'], daily_df['cost_ma_7'], label='7-day MA', linewidth=2)\n",
    "axes[0, 0].set_title('Cost with Moving Average', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Lag features\n",
    "axes[0, 1].scatter(daily_df['cost_lag_1'], daily_df['total_cost'], alpha=0.6)\n",
    "axes[0, 1].set_xlabel('Cost (t-1)')\n",
    "axes[0, 1].set_ylabel('Cost (t)')\n",
    "axes[0, 1].set_title('Cost Autocorrelation (lag=1)', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Day of week pattern\n",
    "daily_df.groupby('day_of_week')['total_cost'].mean().plot(kind='bar', ax=axes[1, 0], color='coral')\n",
    "axes[1, 0].set_title('Average Cost by Day of Week', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Day of Week (0=Monday)')\n",
    "axes[1, 0].set_ylabel('Average Cost')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Weekend vs weekday\n",
    "daily_df.groupby('is_weekend')['total_cost'].mean().plot(kind='bar', ax=axes[1, 1], color='seagreen')\n",
    "axes[1, 1].set_title('Average Cost: Weekday vs Weekend', fontweight='bold')\n",
    "axes[1, 1].set_xticklabels(['Weekday', 'Weekend'], rotation=0)\n",
    "axes[1, 1].set_ylabel('Average Cost')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN (from lag features)\n",
    "df_clean = daily_df.dropna().copy()\n",
    "\n",
    "# Split into train/test (80/20)\n",
    "train_size = int(len(df_clean) * 0.8)\n",
    "train_df = df_clean[:train_size]\n",
    "test_df = df_clean[train_size:]\n",
    "\n",
    "print(f\"Training set: {len(train_df)} days ({train_df['date'].min()} to {train_df['date'].max()})\")\n",
    "print(f\"Test set: {len(test_df)} days ({test_df['date'].min()} to {test_df['date'].max()})\")\n",
    "\n",
    "# Visualize split\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(train_df['date'], train_df['total_cost'], label='Training Data', color='blue')\n",
    "plt.plot(test_df['date'], test_df['total_cost'], label='Test Data', color='orange')\n",
    "plt.axvline(x=train_df['date'].iloc[-1], color='red', linestyle='--', label='Train/Test Split')\n",
    "plt.title('Train/Test Split', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model 1: ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ARIMA\n",
    "train_series = train_df.set_index('date')['total_cost']\n",
    "test_series = test_df.set_index('date')['total_cost']\n",
    "\n",
    "# Fit ARIMA model\n",
    "print(\"Training ARIMA model...\")\n",
    "arima_model = ARIMA(train_series, order=(5, 1, 2))  # (p, d, q)\n",
    "arima_fitted = arima_model.fit()\n",
    "\n",
    "print(\"ARIMA model trained!\")\n",
    "print(arima_fitted.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "arima_predictions = arima_fitted.forecast(steps=len(test_df))\n",
    "\n",
    "# Calculate metrics\n",
    "arima_mae = mean_absolute_error(test_series, arima_predictions)\n",
    "arima_rmse = np.sqrt(mean_squared_error(test_series, arima_predictions))\n",
    "arima_r2 = r2_score(test_series, arima_predictions)\n",
    "\n",
    "print(f\"\\nARIMA Performance:\")\n",
    "print(f\"  MAE: ${arima_mae:.2f}\")\n",
    "print(f\"  RMSE: ${arima_rmse:.2f}\")\n",
    "print(f\"  R²: {arima_r2:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(train_series.index, train_series, label='Training Data', alpha=0.7)\n",
    "plt.plot(test_series.index, test_series, label='Actual Test Data', color='orange', linewidth=2)\n",
    "plt.plot(test_series.index, arima_predictions, label='ARIMA Predictions', \n",
    "         color='red', linestyle='--', linewidth=2)\n",
    "plt.title('ARIMA Forecast', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Cost ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 2: Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Prepare data for Prophet\n",
    "    prophet_train = train_df[['date', 'total_cost']].copy()\n",
    "    prophet_train.columns = ['ds', 'y']\n",
    "    \n",
    "    # Create and train Prophet model\n",
    "    print(\"Training Prophet model...\")\n",
    "    prophet_model = Prophet(\n",
    "        daily_seasonality=False,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False,\n",
    "        changepoint_prior_scale=0.05\n",
    "    )\n",
    "    \n",
    "    # Add custom regressors\n",
    "    prophet_train['is_weekend'] = train_df['is_weekend'].values\n",
    "    prophet_model.add_regressor('is_weekend')\n",
    "    \n",
    "    prophet_model.fit(prophet_train)\n",
    "    print(\"Prophet model trained!\")\n",
    "    \n",
    "    # Make predictions\n",
    "    prophet_future = test_df[['date', 'is_weekend']].copy()\n",
    "    prophet_future.columns = ['ds', 'is_weekend']\n",
    "    prophet_forecast = prophet_model.predict(prophet_future)\n",
    "    prophet_predictions = prophet_forecast['yhat'].values\n",
    "    \n",
    "    # Calculate metrics\n",
    "    prophet_mae = mean_absolute_error(test_series, prophet_predictions)\n",
    "    prophet_rmse = np.sqrt(mean_squared_error(test_series, prophet_predictions))\n",
    "    prophet_r2 = r2_score(test_series, prophet_predictions)\n",
    "    \n",
    "    print(f\"\\nProphet Performance:\")\n",
    "    print(f\"  MAE: ${prophet_mae:.2f}\")\n",
    "    print(f\"  RMSE: ${prophet_rmse:.2f}\")\n",
    "    print(f\"  R²: {prophet_r2:.4f}\")\n",
    "else:\n",
    "    print(\"Prophet not available. Skipping Prophet model.\")\n",
    "    prophet_predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROPHET_AVAILABLE:\n",
    "    # Visualize Prophet forecast\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(train_series.index, train_series, label='Training Data', alpha=0.7)\n",
    "    plt.plot(test_series.index, test_series, label='Actual Test Data', color='orange', linewidth=2)\n",
    "    plt.plot(test_series.index, prophet_predictions, label='Prophet Predictions', \n",
    "             color='green', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # Add confidence interval\n",
    "    plt.fill_between(test_series.index, \n",
    "                     prophet_forecast['yhat_lower'].values,\n",
    "                     prophet_forecast['yhat_upper'].values,\n",
    "                     alpha=0.2, color='green', label='95% Confidence')\n",
    "    \n",
    "    plt.title('Prophet Forecast', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Total Cost ($)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 3: LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Prepare data for LSTM\n",
    "    feature_cols = ['cost_lag_1', 'cost_lag_3', 'cost_lag_7', 'cost_ma_7', 'cost_ma_14',\n",
    "                   'day_of_week', 'is_weekend', 'trend']\n",
    "    \n",
    "    X_train = train_df[feature_cols].values\n",
    "    y_train = train_df['total_cost'].values\n",
    "    X_test = test_df[feature_cols].values\n",
    "    y_test = test_df['total_cost'].values\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    \n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "    \n",
    "    # Reshape for LSTM (samples, timesteps, features)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    \n",
    "    print(f\"Training data shape: {X_train_lstm.shape}\")\n",
    "    print(f\"Test data shape: {X_test_lstm.shape}\")\n",
    "else:\n",
    "    print(\"TensorFlow not available. Skipping LSTM model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Build LSTM model\n",
    "    print(\"Building LSTM model...\")\n",
    "    lstm_model = Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, \n",
    "             input_shape=(1, len(feature_cols))),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    print(lstm_model.summary())\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining LSTM model...\")\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = lstm_model.fit(\n",
    "        X_train_lstm, y_train_scaled,\n",
    "        epochs=100,\n",
    "        batch_size=8,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    print(\"LSTM model trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Make predictions\n",
    "    lstm_predictions_scaled = lstm_model.predict(X_test_lstm, verbose=0)\n",
    "    lstm_predictions = scaler_y.inverse_transform(lstm_predictions_scaled).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    lstm_mae = mean_absolute_error(y_test, lstm_predictions)\n",
    "    lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "    lstm_r2 = r2_score(y_test, lstm_predictions)\n",
    "    \n",
    "    print(f\"\\nLSTM Performance:\")\n",
    "    print(f\"  MAE: ${lstm_mae:.2f}\")\n",
    "    print(f\"  RMSE: ${lstm_rmse:.2f}\")\n",
    "    print(f\"  R²: {lstm_r2:.4f}\")\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0].set_title('Model Loss', fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(history.history['mae'], label='Training MAE')\n",
    "    axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
    "    axes[1].set_title('Model MAE', fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('MAE')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize predictions\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(train_series.index, train_series, label='Training Data', alpha=0.7)\n",
    "    plt.plot(test_series.index, test_series, label='Actual Test Data', color='orange', linewidth=2)\n",
    "    plt.plot(test_series.index, lstm_predictions, label='LSTM Predictions', \n",
    "             color='purple', linestyle='--', linewidth=2)\n",
    "    plt.title('LSTM Forecast', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Total Cost ($)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "    'Model': 'ARIMA',\n",
    "    'MAE': arima_mae,\n",
    "    'RMSE': arima_rmse,\n",
    "    'R²': arima_r2\n",
    "})\n",
    "\n",
    "if PROPHET_AVAILABLE:\n",
    "    results.append({\n",
    "        'Model': 'Prophet',\n",
    "        'MAE': prophet_mae,\n",
    "        'RMSE': prophet_rmse,\n",
    "        'R²': prophet_r2\n",
    "    })\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    results.append({\n",
    "        'Model': 'LSTM',\n",
    "        'MAE': lstm_mae,\n",
    "        'RMSE': lstm_rmse,\n",
    "        'R²': lstm_r2\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"\\nBest Model (by MAE): \" + results_df.loc[results_df['MAE'].idxmin(), 'Model'])\n",
    "print(\"Best Model (by R²): \" + results_df.loc[results_df['R²'].idxmax(), 'Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# MAE comparison\n",
    "results_df.plot(x='Model', y='MAE', kind='bar', ax=axes[0], legend=False, color='steelblue')\n",
    "axes[0].set_title('Mean Absolute Error', fontweight='bold')\n",
    "axes[0].set_ylabel('MAE ($)')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE comparison\n",
    "results_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[1], legend=False, color='coral')\n",
    "axes[1].set_title('Root Mean Squared Error', fontweight='bold')\n",
    "axes[1].set_ylabel('RMSE ($)')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R² comparison\n",
    "results_df.plot(x='Model', y='R²', kind='bar', ax=axes[2], legend=False, color='seagreen')\n",
    "axes[2].set_title('R² Score', fontweight='bold')\n",
    "axes[2].set_ylabel('R²')\n",
    "axes[2].tick_params(axis='x', rotation=0)\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all predictions visually\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "plt.plot(train_series.index, train_series, label='Training Data', alpha=0.5, color='gray')\n",
    "plt.plot(test_series.index, test_series, label='Actual', color='black', linewidth=2.5)\n",
    "plt.plot(test_series.index, arima_predictions, label='ARIMA', linestyle='--', linewidth=2)\n",
    "\n",
    "if PROPHET_AVAILABLE:\n",
    "    plt.plot(test_series.index, prophet_predictions, label='Prophet', linestyle='--', linewidth=2)\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    plt.plot(test_series.index, lstm_predictions, label='LSTM', linestyle='--', linewidth=2)\n",
    "\n",
    "plt.title('All Model Predictions Comparison', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Total Cost ($)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model (example with Prophet)\n",
    "if PROPHET_AVAILABLE:\n",
    "    import pickle\n",
    "    \n",
    "    # Save Prophet model\n",
    "    with open('prophet_cost_model.pkl', 'wb') as f:\n",
    "        pickle.dump(prophet_model, f)\n",
    "    print(\"Prophet model saved as 'prophet_cost_model.pkl'\")\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    # Save LSTM model\n",
    "    lstm_model.save('lstm_cost_model.h5')\n",
    "    print(\"LSTM model saved as 'lstm_cost_model.h5'\")\n",
    "    \n",
    "    # Save scalers\n",
    "    with open('lstm_scalers.pkl', 'wb') as f:\n",
    "        pickle.dump({'scaler_X': scaler_X, 'scaler_y': scaler_y}, f)\n",
    "    print(\"LSTM scalers saved as 'lstm_scalers.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create production prediction function\n",
    "def predict_future_costs(days_ahead=30, model_type='prophet'):\n",
    "    \"\"\"\n",
    "    Predict future costs using the specified model.\n",
    "    \n",
    "    Parameters:\n",
    "    - days_ahead: Number of days to forecast\n",
    "    - model_type: 'prophet', 'arima', or 'lstm'\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with predictions\n",
    "    \"\"\"\n",
    "    if model_type == 'prophet' and PROPHET_AVAILABLE:\n",
    "        # Create future dataframe\n",
    "        last_date = daily_df['date'].max()\n",
    "        future_dates = pd.date_range(start=last_date + timedelta(days=1), \n",
    "                                     periods=days_ahead, freq='D')\n",
    "        \n",
    "        future_df = pd.DataFrame({\n",
    "            'ds': future_dates,\n",
    "            'is_weekend': [1 if d.dayofweek in [5, 6] else 0 for d in future_dates]\n",
    "        })\n",
    "        \n",
    "        # Make predictions\n",
    "        forecast = prophet_model.predict(future_df)\n",
    "        \n",
    "        result = pd.DataFrame({\n",
    "            'date': forecast['ds'],\n",
    "            'predicted_cost': forecast['yhat'],\n",
    "            'lower_bound': forecast['yhat_lower'],\n",
    "            'upper_bound': forecast['yhat_upper']\n",
    "        })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        print(f\"Model type '{model_type}' not available or not supported.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "print(\"\\nProduction prediction function created!\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  predictions = predict_future_costs(days_ahead=30, model_type='prophet')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 30-day forecast\n",
    "if PROPHET_AVAILABLE:\n",
    "    future_predictions = predict_future_costs(days_ahead=30, model_type='prophet')\n",
    "    \n",
    "    if future_predictions is not None:\n",
    "        print(\"\\n30-Day Cost Forecast:\")\n",
    "        print(future_predictions.head(10))\n",
    "        \n",
    "        print(f\"\\nTotal Predicted Cost (30 days): ${future_predictions['predicted_cost'].sum():.2f}\")\n",
    "        print(f\"Average Daily Cost: ${future_predictions['predicted_cost'].mean():.2f}\")\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(daily_df['date'], daily_df['total_cost'], label='Historical', alpha=0.7)\n",
    "        plt.plot(future_predictions['date'], future_predictions['predicted_cost'], \n",
    "                label='Forecast', color='red', linewidth=2)\n",
    "        plt.fill_between(future_predictions['date'],\n",
    "                        future_predictions['lower_bound'],\n",
    "                        future_predictions['upper_bound'],\n",
    "                        alpha=0.2, color='red', label='95% Confidence')\n",
    "        plt.title('30-Day Cost Forecast', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Cost ($)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "output_dir = 'ml_forecasting_output'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save model comparison\n",
    "results_df.to_csv(f'{output_dir}/model_comparison.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/model_comparison.csv\")\n",
    "\n",
    "# Save future predictions\n",
    "if PROPHET_AVAILABLE and future_predictions is not None:\n",
    "    future_predictions.to_csv(f'{output_dir}/30day_forecast.csv', index=False)\n",
    "    print(f\"Saved: {output_dir}/30day_forecast.csv\")\n",
    "\n",
    "# Save feature importance (for reference)\n",
    "feature_info = pd.DataFrame({\n",
    "    'Feature': feature_cols if TENSORFLOW_AVAILABLE else [],\n",
    "    'Description': [\n",
    "        'Cost 1 day ago',\n",
    "        'Cost 3 days ago',\n",
    "        'Cost 7 days ago',\n",
    "        '7-day moving average',\n",
    "        '14-day moving average',\n",
    "        'Day of week (0-6)',\n",
    "        'Weekend indicator',\n",
    "        'Linear trend'\n",
    "    ] if TENSORFLOW_AVAILABLE else []\n",
    "})\n",
    "\n",
    "if TENSORFLOW_AVAILABLE:\n",
    "    feature_info.to_csv(f'{output_dir}/features.csv', index=False)\n",
    "    print(f\"Saved: {output_dir}/features.csv\")\n",
    "\n",
    "print(f\"\\nAll results exported to '{output_dir}/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- Feature engineering for time series forecasting\n",
    "- Training and evaluating multiple forecasting models:\n",
    "  - ARIMA for statistical time series forecasting\n",
    "  - Prophet for robust forecasting with seasonality\n",
    "  - LSTM neural networks for deep learning-based forecasting\n",
    "- Model comparison and selection\n",
    "- Production deployment considerations\n",
    "\n",
    "## Best Practices for Production\n",
    "1. **Model Retraining**: Retrain models regularly with new data\n",
    "2. **Monitoring**: Track prediction accuracy and drift\n",
    "3. **Ensemble Methods**: Consider combining multiple models\n",
    "4. **Feature Updates**: Keep feature engineering pipeline current\n",
    "5. **Version Control**: Track model versions and performance\n",
    "\n",
    "## Next Steps\n",
    "- Deploy the best model to production\n",
    "- Set up automated retraining pipeline\n",
    "- Implement monitoring and alerting\n",
    "- Explore ensemble methods for improved accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
