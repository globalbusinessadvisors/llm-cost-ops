{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Optimization Analysis\n",
    "\n",
    "This notebook focuses on practical cost optimization strategies and analysis techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "- Compare costs across different LLM models\n",
    "- Analyze token efficiency and optimization opportunities\n",
    "- Evaluate cost-performance tradeoffs\n",
    "- Calculate ROI for different optimization strategies\n",
    "- Generate actionable recommendations\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install pandas matplotlib seaborn numpy requests scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Cost Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "BASE_URL = 'http://localhost:3000/api'\n",
    "API_KEY = 'your-api-key-here'\n",
    "HEADERS = {\n",
    "    'Authorization': f'Bearer {API_KEY}',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Fetch data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "params = {\n",
    "    'start_date': start_date.isoformat(),\n",
    "    'end_date': end_date.isoformat(),\n",
    "    'limit': 5000\n",
    "}\n",
    "\n",
    "response = requests.get(f'{BASE_URL}/cost-tracking', headers=HEADERS, params=params)\n",
    "cost_data = response.json()\n",
    "\n",
    "df = pd.DataFrame(cost_data['data'])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['total_tokens'] = df['input_tokens'] + df['output_tokens']\n",
    "df['cost_per_1k_tokens'] = (df['total_cost'] / df['total_tokens'] * 1000).round(4)\n",
    "\n",
    "print(f\"Loaded {len(df)} cost records\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Models: {df['model'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Cost Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model comparison\n",
    "model_comparison = df.groupby('model').agg({\n",
    "    'total_cost': ['sum', 'mean', 'median', 'std'],\n",
    "    'request_id': 'count',\n",
    "    'total_tokens': 'sum',\n",
    "    'input_tokens': 'sum',\n",
    "    'output_tokens': 'sum',\n",
    "    'cost_per_1k_tokens': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "model_comparison.columns = ['_'.join(col).strip() for col in model_comparison.columns.values]\n",
    "model_comparison = model_comparison.rename(columns={\n",
    "    'total_cost_sum': 'total_cost',\n",
    "    'total_cost_mean': 'avg_cost_per_request',\n",
    "    'total_cost_median': 'median_cost_per_request',\n",
    "    'total_cost_std': 'cost_std_dev',\n",
    "    'request_id_count': 'request_count',\n",
    "    'total_tokens_sum': 'total_tokens',\n",
    "    'input_tokens_sum': 'input_tokens',\n",
    "    'output_tokens_sum': 'output_tokens',\n",
    "    'cost_per_1k_tokens_mean': 'avg_cost_per_1k_tokens'\n",
    "})\n",
    "\n",
    "# Calculate percentages\n",
    "total_cost_all = model_comparison['total_cost'].sum()\n",
    "model_comparison['cost_percentage'] = (model_comparison['total_cost'] / total_cost_all * 100).round(2)\n",
    "\n",
    "# Sort by total cost\n",
    "model_comparison = model_comparison.sort_values('total_cost', ascending=False)\n",
    "\n",
    "print(\"Model Cost Comparison:\")\n",
    "print(\"=\"*100)\n",
    "print(model_comparison[['total_cost', 'request_count', 'avg_cost_per_request', \n",
    "                         'avg_cost_per_1k_tokens', 'cost_percentage']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model cost comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Total cost by model\n",
    "ax1 = axes[0, 0]\n",
    "model_comparison['total_cost'].plot(kind='bar', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Total Cost by Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Total Cost ($)')\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Average cost per request\n",
    "ax2 = axes[0, 1]\n",
    "model_comparison['avg_cost_per_request'].plot(kind='bar', ax=ax2, color='coral')\n",
    "ax2.set_title('Average Cost per Request', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Avg Cost ($)')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Cost per 1K tokens\n",
    "ax3 = axes[1, 0]\n",
    "model_comparison['avg_cost_per_1k_tokens'].plot(kind='bar', ax=ax3, color='seagreen')\n",
    "ax3.set_title('Average Cost per 1K Tokens', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Cost per 1K Tokens ($)')\n",
    "ax3.set_xlabel('Model')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Request distribution\n",
    "ax4 = axes[1, 1]\n",
    "model_comparison['request_count'].plot(kind='bar', ax=ax4, color='mediumpurple')\n",
    "ax4.set_title('Request Count by Model', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('Number of Requests')\n",
    "ax4.set_xlabel('Model')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Token Efficiency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate token efficiency metrics\n",
    "token_efficiency = df.groupby('model').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'avg_input_tokens': x['input_tokens'].mean(),\n",
    "        'avg_output_tokens': x['output_tokens'].mean(),\n",
    "        'avg_total_tokens': x['total_tokens'].mean(),\n",
    "        'input_output_ratio': x['input_tokens'].sum() / x['output_tokens'].sum() if x['output_tokens'].sum() > 0 else 0,\n",
    "        'tokens_per_dollar': (x['total_tokens'].sum() / x['total_cost'].sum()) if x['total_cost'].sum() > 0 else 0\n",
    "    })\n",
    ").round(2)\n",
    "\n",
    "print(\"Token Efficiency by Model:\")\n",
    "print(\"=\"*80)\n",
    "print(token_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize token efficiency\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Input vs Output tokens\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(token_efficiency))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, token_efficiency['avg_input_tokens'], width, label='Input Tokens', alpha=0.8)\n",
    "ax1.bar(x + width/2, token_efficiency['avg_output_tokens'], width, label='Output Tokens', alpha=0.8)\n",
    "ax1.set_title('Average Token Usage by Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Average Tokens per Request')\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(token_efficiency.index, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Tokens per dollar (value)\n",
    "ax2 = axes[1]\n",
    "token_efficiency['tokens_per_dollar'].plot(kind='bar', ax=ax2, color='gold')\n",
    "ax2.set_title('Token Value (Tokens per Dollar)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Tokens per Dollar')\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cost-Performance Tradeoff Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance score (normalized combination of efficiency metrics)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "performance_df = model_comparison[['avg_cost_per_request', 'avg_cost_per_1k_tokens']].copy()\n",
    "performance_df['cost_score'] = scaler.fit_transform(1 / performance_df[['avg_cost_per_request']])\n",
    "performance_df['efficiency_score'] = scaler.fit_transform(token_efficiency[['tokens_per_dollar']])\n",
    "performance_df['overall_score'] = (performance_df['cost_score'] + performance_df['efficiency_score']) / 2\n",
    "\n",
    "performance_df = performance_df.sort_values('overall_score', ascending=False)\n",
    "\n",
    "print(\"Cost-Performance Analysis:\")\n",
    "print(\"=\"*80)\n",
    "print(performance_df[['cost_score', 'efficiency_score', 'overall_score']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Cost vs Efficiency\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for model in model_comparison.index:\n",
    "    x = model_comparison.loc[model, 'avg_cost_per_1k_tokens']\n",
    "    y = token_efficiency.loc[model, 'tokens_per_dollar']\n",
    "    size = model_comparison.loc[model, 'request_count'] / 10\n",
    "    \n",
    "    ax.scatter(x, y, s=size, alpha=0.6, label=model)\n",
    "    ax.annotate(model, (x, y), xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax.set_title('Cost-Performance Tradeoff (bubble size = request count)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Average Cost per 1K Tokens ($)', fontsize=12)\n",
    "ax.set_ylabel('Tokens per Dollar', fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimization Opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential savings by switching models\n",
    "print(\"OPTIMIZATION OPPORTUNITIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find the most cost-effective model\n",
    "best_model = performance_df['overall_score'].idxmax()\n",
    "best_cost_per_1k = model_comparison.loc[best_model, 'avg_cost_per_1k_tokens']\n",
    "\n",
    "print(f\"\\nMost Cost-Effective Model: {best_model}\")\n",
    "print(f\"Cost per 1K tokens: ${best_cost_per_1k:.4f}\")\n",
    "\n",
    "# Calculate potential savings\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Potential Savings by Switching to Most Cost-Effective Model:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "total_potential_savings = 0\n",
    "\n",
    "for model in model_comparison.index:\n",
    "    if model != best_model:\n",
    "        current_cost = model_comparison.loc[model, 'total_cost']\n",
    "        total_tokens = model_comparison.loc[model, 'total_tokens']\n",
    "        potential_cost = (total_tokens / 1000) * best_cost_per_1k\n",
    "        savings = current_cost - potential_cost\n",
    "        savings_pct = (savings / current_cost * 100) if current_cost > 0 else 0\n",
    "        \n",
    "        if savings > 0:\n",
    "            total_potential_savings += savings\n",
    "            print(f\"\\n{model}:\")\n",
    "            print(f\"  Current Cost: ${current_cost:.2f}\")\n",
    "            print(f\"  Potential Cost with {best_model}: ${potential_cost:.2f}\")\n",
    "            print(f\"  Potential Savings: ${savings:.2f} ({savings_pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOTAL POTENTIAL SAVINGS: ${total_potential_savings:.2f}\")\n",
    "print(f\"Current Total Cost: ${model_comparison['total_cost'].sum():.2f}\")\n",
    "print(f\"Potential Total Cost: ${model_comparison['total_cost'].sum() - total_potential_savings:.2f}\")\n",
    "print(f\"Overall Savings: {(total_potential_savings / model_comparison['total_cost'].sum() * 100):.1f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token usage optimization opportunities\n",
    "print(\"\\nTOKEN USAGE OPTIMIZATION OPPORTUNITIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find requests with unusually high token usage\n",
    "token_percentile_95 = df['total_tokens'].quantile(0.95)\n",
    "high_token_requests = df[df['total_tokens'] > token_percentile_95]\n",
    "\n",
    "print(f\"\\nHigh Token Usage Requests (>95th percentile, {token_percentile_95:.0f} tokens):\")\n",
    "print(f\"Count: {len(high_token_requests)}\")\n",
    "print(f\"Total Cost: ${high_token_requests['total_cost'].sum():.2f}\")\n",
    "print(f\"Average Cost: ${high_token_requests['total_cost'].mean():.4f}\")\n",
    "print(f\"\\nBreakdown by Model:\")\n",
    "print(high_token_requests.groupby('model').agg({\n",
    "    'request_id': 'count',\n",
    "    'total_cost': 'sum',\n",
    "    'total_tokens': 'mean'\n",
    "}).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ROI Calculation for Optimization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROI for different optimization strategies\n",
    "print(\"ROI ANALYSIS FOR OPTIMIZATION STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Strategy 1: Switch to most cost-effective model\n",
    "print(\"\\nStrategy 1: Switch all requests to most cost-effective model\")\n",
    "print(\"-\"*80)\n",
    "implementation_cost_1 = 500  # Estimated implementation cost\n",
    "monthly_savings_1 = total_potential_savings\n",
    "roi_months_1 = implementation_cost_1 / monthly_savings_1 if monthly_savings_1 > 0 else float('inf')\n",
    "annual_savings_1 = monthly_savings_1 * 12\n",
    "\n",
    "print(f\"Implementation Cost: ${implementation_cost_1:.2f}\")\n",
    "print(f\"Monthly Savings: ${monthly_savings_1:.2f}\")\n",
    "print(f\"Annual Savings: ${annual_savings_1:.2f}\")\n",
    "print(f\"ROI Period: {roi_months_1:.1f} months\")\n",
    "print(f\"12-Month ROI: {((annual_savings_1 - implementation_cost_1) / implementation_cost_1 * 100):.1f}%\")\n",
    "\n",
    "# Strategy 2: Implement prompt optimization\n",
    "print(\"\\n\\nStrategy 2: Implement prompt optimization (reduce tokens by 20%)\")\n",
    "print(\"-\"*80)\n",
    "implementation_cost_2 = 2000  # Higher cost for prompt engineering\n",
    "token_reduction = 0.20\n",
    "monthly_savings_2 = model_comparison['total_cost'].sum() * token_reduction\n",
    "roi_months_2 = implementation_cost_2 / monthly_savings_2 if monthly_savings_2 > 0 else float('inf')\n",
    "annual_savings_2 = monthly_savings_2 * 12\n",
    "\n",
    "print(f\"Implementation Cost: ${implementation_cost_2:.2f}\")\n",
    "print(f\"Expected Token Reduction: {token_reduction*100:.0f}%\")\n",
    "print(f\"Monthly Savings: ${monthly_savings_2:.2f}\")\n",
    "print(f\"Annual Savings: ${annual_savings_2:.2f}\")\n",
    "print(f\"ROI Period: {roi_months_2:.1f} months\")\n",
    "print(f\"12-Month ROI: {((annual_savings_2 - implementation_cost_2) / implementation_cost_2 * 100):.1f}%\")\n",
    "\n",
    "# Strategy 3: Implement caching\n",
    "print(\"\\n\\nStrategy 3: Implement response caching (30% cache hit rate)\")\n",
    "print(\"-\"*80)\n",
    "implementation_cost_3 = 1500\n",
    "cache_hit_rate = 0.30\n",
    "monthly_savings_3 = model_comparison['total_cost'].sum() * cache_hit_rate\n",
    "roi_months_3 = implementation_cost_3 / monthly_savings_3 if monthly_savings_3 > 0 else float('inf')\n",
    "annual_savings_3 = monthly_savings_3 * 12\n",
    "\n",
    "print(f\"Implementation Cost: ${implementation_cost_3:.2f}\")\n",
    "print(f\"Expected Cache Hit Rate: {cache_hit_rate*100:.0f}%\")\n",
    "print(f\"Monthly Savings: ${monthly_savings_3:.2f}\")\n",
    "print(f\"Annual Savings: ${annual_savings_3:.2f}\")\n",
    "print(f\"ROI Period: {roi_months_3:.1f} months\")\n",
    "print(f\"12-Month ROI: {((annual_savings_3 - implementation_cost_3) / implementation_cost_3 * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ROI comparison\n",
    "strategies = [\n",
    "    {'name': 'Model Switch', 'cost': implementation_cost_1, 'monthly_savings': monthly_savings_1},\n",
    "    {'name': 'Prompt Optimization', 'cost': implementation_cost_2, 'monthly_savings': monthly_savings_2},\n",
    "    {'name': 'Response Caching', 'cost': implementation_cost_3, 'monthly_savings': monthly_savings_3}\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Monthly savings comparison\n",
    "ax1 = axes[0]\n",
    "names = [s['name'] for s in strategies]\n",
    "savings = [s['monthly_savings'] for s in strategies]\n",
    "ax1.bar(names, savings, color=['steelblue', 'coral', 'seagreen'], alpha=0.8)\n",
    "ax1.set_title('Monthly Savings by Strategy', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Monthly Savings ($)')\n",
    "ax1.tick_params(axis='x', rotation=15)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# ROI timeline\n",
    "ax2 = axes[1]\n",
    "months = np.arange(0, 13)\n",
    "for strategy in strategies:\n",
    "    net_benefit = months * strategy['monthly_savings'] - strategy['cost']\n",
    "    ax2.plot(months, net_benefit, marker='o', label=strategy['name'], linewidth=2)\n",
    "\n",
    "ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "ax2.set_title('ROI Timeline (12 Months)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Months')\n",
    "ax2.set_ylabel('Net Benefit ($)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimization Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prioritized recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRIORITIZED OPTIMIZATION RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Recommendation 1: Model optimization\n",
    "if total_potential_savings > 0:\n",
    "    recommendations.append({\n",
    "        'priority': 'HIGH',\n",
    "        'title': f'Switch to {best_model} for cost savings',\n",
    "        'impact': f'${total_potential_savings:.2f}/month',\n",
    "        'effort': 'Low',\n",
    "        'description': f'Migrating appropriate workloads to {best_model} could save {(total_potential_savings / model_comparison[\"total_cost\"].sum() * 100):.1f}% of total costs.'\n",
    "    })\n",
    "\n",
    "# Recommendation 2: High token usage\n",
    "if len(high_token_requests) > 0:\n",
    "    high_token_cost = high_token_requests['total_cost'].sum()\n",
    "    high_token_pct = len(high_token_requests) / len(df) * 100\n",
    "    recommendations.append({\n",
    "        'priority': 'HIGH',\n",
    "        'title': 'Optimize high-token requests',\n",
    "        'impact': f'Potential ${high_token_cost * 0.3:.2f}/month (30% reduction)',\n",
    "        'effort': 'Medium',\n",
    "        'description': f'{high_token_pct:.1f}% of requests use excessive tokens. Implement prompt optimization and input validation.'\n",
    "    })\n",
    "\n",
    "# Recommendation 3: Caching\n",
    "recommendations.append({\n",
    "    'priority': 'MEDIUM',\n",
    "    'title': 'Implement response caching',\n",
    "    'impact': f'${monthly_savings_3:.2f}/month',\n",
    "    'effort': 'Medium',\n",
    "    'description': 'With an estimated 30% cache hit rate, caching could significantly reduce costs.'\n",
    "})\n",
    "\n",
    "# Recommendation 4: Rate limiting during peak hours\n",
    "recommendations.append({\n",
    "    'priority': 'LOW',\n",
    "    'title': 'Implement smart rate limiting',\n",
    "    'effort': 'Low',\n",
    "    'impact': 'Variable',\n",
    "    'description': 'Implement request batching and rate limiting to optimize API usage patterns.'\n",
    "})\n",
    "\n",
    "# Print recommendations\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"\\n{i}. [{rec['priority']} PRIORITY] {rec['title']}\")\n",
    "    print(f\"   Impact: {rec['impact']}\")\n",
    "    print(f\"   Effort: {rec['effort']}\")\n",
    "    print(f\"   Details: {rec['description']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create Optimization Action Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create action plan DataFrame\n",
    "action_plan = pd.DataFrame(recommendations)\n",
    "action_plan['priority_order'] = action_plan['priority'].map({'HIGH': 1, 'MEDIUM': 2, 'LOW': 3})\n",
    "action_plan = action_plan.sort_values('priority_order')\n",
    "\n",
    "print(\"\\nOPTIMIZATION ACTION PLAN\")\n",
    "print(\"=\"*80)\n",
    "print(action_plan[['priority', 'title', 'impact', 'effort']].to_string(index=False))\n",
    "\n",
    "# Calculate total potential impact\n",
    "total_impact = monthly_savings_1 + (high_token_requests['total_cost'].sum() * 0.3) + monthly_savings_3\n",
    "print(f\"\\n\\nEstimated Total Monthly Impact: ${total_impact:.2f}\")\n",
    "print(f\"Estimated Annual Impact: ${total_impact * 12:.2f}\")\n",
    "print(f\"Current Monthly Cost: ${model_comparison['total_cost'].sum():.2f}\")\n",
    "print(f\"Optimized Monthly Cost: ${model_comparison['total_cost'].sum() - total_impact:.2f}\")\n",
    "print(f\"Total Potential Savings: {(total_impact / model_comparison['total_cost'].sum() * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Optimization Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "output_dir = 'cost_optimization_output'\n",
    "import os\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export model comparison\n",
    "model_comparison.to_csv(f'{output_dir}/model_comparison.csv')\n",
    "print(f\"Saved: {output_dir}/model_comparison.csv\")\n",
    "\n",
    "# Export token efficiency\n",
    "token_efficiency.to_csv(f'{output_dir}/token_efficiency.csv')\n",
    "print(f\"Saved: {output_dir}/token_efficiency.csv\")\n",
    "\n",
    "# Export performance analysis\n",
    "performance_df.to_csv(f'{output_dir}/performance_analysis.csv')\n",
    "print(f\"Saved: {output_dir}/performance_analysis.csv\")\n",
    "\n",
    "# Export high token requests\n",
    "high_token_requests.to_csv(f'{output_dir}/high_token_requests.csv', index=False)\n",
    "print(f\"Saved: {output_dir}/high_token_requests.csv\")\n",
    "\n",
    "# Export action plan\n",
    "action_plan[['priority', 'title', 'impact', 'effort', 'description']].to_csv(\n",
    "    f'{output_dir}/action_plan.csv', index=False\n",
    ")\n",
    "print(f\"Saved: {output_dir}/action_plan.csv\")\n",
    "\n",
    "print(f\"\\nAll optimization reports exported to '{output_dir}/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- How to compare costs across different LLM models\n",
    "- Techniques for analyzing token efficiency\n",
    "- Methods for evaluating cost-performance tradeoffs\n",
    "- ROI calculations for optimization strategies\n",
    "- How to generate actionable recommendations\n",
    "\n",
    "## Next Steps\n",
    "- **04_custom_reports.ipynb** - Build custom reporting dashboards\n",
    "- **05_ml_forecasting.ipynb** - Advanced ML forecasting techniques\n",
    "- Implement the recommended optimizations\n",
    "- Monitor results and iterate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
